doctype html 
html  
  head  
    meta(charset = 'UTF-8')
    title A Synergistic framework Base on Halide
    link(rel="stylesheet", href="css/reveal.css")  
    link(rel="stylesheet", href="css/theme/night.css",id="theme")
    link(rel="stylesheet", href="lib/css/zenburn.css")
  script.
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );


  body  
    .reveal
      .slides
        section
          section  
            h1 A Synergistic framework 
            h1 base on Halide
            p 
              small present by 
                a(href="https://tw.linkedin.com/pub/ken-kuang/9a/890/678") Ken Kuang  
        section
          h1 Outline
          each title,index in ["Motivation","Background","Implementation","Experiment Result","Conclusion"]
            h3 
            a(href="#/"+(index+2))=title          
        section
          section
            h1 Motivation
          section
            h3 Halide is a new language
            h4 which is designed to make it <span class="fragment highlight-red"><strong>easier</strong></span> to write <span class="fragment highlight-blue"><strong>high-performance</strong></span> image processing code.
          section
            h3 It can support CPU and GPU backend.
            h4 So we want to make a <span class="fragment highlight-blue"><strong>synergistic framework</strong></span> as Halide extension 
          section
            h4 It’s several research target on synergistically computing 
            h4 by using Heterogeneous computing language like OpenCL.
          section       
            h3 But OpenCL is difficult to
            ul
              li(class="fragment highlight-red") Program
              li(class="fragment highlight-red") Tune performance  
          section
            h3 It makes Programming heterogeneous computing systems become
            ul
              li(class="fragment highlight-red") Complex
              li(class="fragment highlight-red") Time-consuming
          section
            h3 We hope to take the advangtages of Halide
            h4 to create a better synergistically computing environment
        section
          section
            h1 Background 
            ul 
              li Halide
              li OpenCL
              li Related work - FluidiCL
          section
            h2 Halide decouple algorithm from schedule
            ul
              li Algorithm : <span class="fragment highlight-red"><strong>What</strong></span> is computed
              li Schedule  : <span class="fragment highlight-red"><strong>Where</strong></span> and <span class="fragment highlight-red"><strong>When</strong></span> its' computed
          section
            p Easy for programmers to build pipelines                
            ul
              li simplifies algorithm code                           
              li improves modularity
            p Easy for programmers to specify & explore optimizations
            ul
              li fusion, tiling, parallelism, vectorization          
              li can’t break the algorithm
            p Easy for the compiler to generate fast code
          section 
            h2 Native C++ Code
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              Image&lt;uint16_t&gt; blur(Image&lt;uint16_t&gt; in) {
                Image&lt;uint16_t&gt; tmp(in.width()-8, in.height());
                Image&lt;uint16_t&gt; out(in.width()-8, in.height()-2);                    
                for (int y = 0; y &lt; tmp.height(); y++)
                    for (int x = 0; x &lt; tmp.width(); x++)
                        tmp(x, y) = (in(x, y) + in(x+1, y) + in(x+2, y))/3;
                for (int y = 0; y &lt; out.height(); y++)
                    for (int x = 0; x &lt; out.width(); x++)
                        out(x, y) = (tmp(x, y) + tmp(x, y+1) + tmp(x, y+2))/3;
                return out;
              }       
              </code>    
          section 
            h2 OpenMP Code
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              Image&ltuint16_t&gt blur_fast(Image&ltuint16_t&gt in) {
                  Image&ltuint16_t&gt out(in.width()-8, in.height()-2);
                  begin_timing;
                  __m128i one_third = _mm_set1_epi16(21846);
              #pragma omp parallel for
                  for (int yTile = 0; yTile &lt out.height(); yTile += 32) {
                      __m128i a, b, c, sum, avg;
                      __m128i tmp[(128/8) * (32 + 2)];
                      for (int xTile = 0; xTile &lt out.width(); xTile += 128) {
                          __m128i *tmpPtr = tmp;
                          for (int y = 0; y &lt 32+2; y++) {
                              const uint16_t *inPtr = &(in(xTile, yTile+y));
                              for (int x = 0; x &lt 128; x += 8) {
                                  a = _mm_load_si128((__m128i*)(inPtr));
                                  b = _mm_loadu_si128((__m128i*)(inPtr+1));
                                  c = _mm_loadu_si128((__m128i*)(inPtr+2));
                                  sum = _mm_add_epi16(_mm_add_epi16(a, b), c);
                                  avg = _mm_mulhi_epi16(sum, one_third);
                                  _mm_store_si128(tmpPtr++, avg);
                                  inPtr+=8;
                              }
                          }
                          tmpPtr = tmp;
                          for (int y = 0; y &lt 32; y++) {
                              __m128i *outPtr = (__m128i *)(&(out(xTile, yTile+y)));
                              for (int x = 0; x &lt 128; x += 8) {
                                  a = _mm_load_si128(tmpPtr+(2*128)/8);
                                  b = _mm_load_si128(tmpPtr+128/8);
                                  c = _mm_load_si128(tmpPtr++);
                                  sum = _mm_add_epi16(_mm_add_epi16(a, b), c);
                                  avg = _mm_mulhi_epi16(sum, one_third);
                                  _mm_store_si128(outPtr++, avg);
                              }
                          }
                      }
                  }
                  end_timing;
                  return out;
                }    
                </code>
          section 
            h2 Halide Code
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              ImageParam input(UInt(16), 2);
              Func blur_x("blur_x"), blur_y("blur_y");
              Var x("x"), y("y"), xi("xi"), yi("yi");

              // The algorithm
              blur_x(x, y) = (input(x, y) + input(x+1, y) + input(x+2, y))/3;
              blur_y(x, y) = (blur_x(x, y) + blur_x(x, y+1) + blur_x(x, y+2))/3;

              // How to schedule it
              blur_y.split(y, y, yi, 8).parallel(y).vectorize(x, 8);
              blur_x.store_at(blur_y, y).compute_at(blur_y, yi).vectorize(x, 8);

              blur_y.compile_to_file("halide_blur", input);              
              </code>
          section
            h2 Halide Pipelines
            img(src="photos/HalidePipeline.png",height="500px")
          section
            h2 Halide Consumer/Producer Relastions
            img(src="photos/HalideConsumerRelations.png",height="500px")
          section 
            h2 Halide CodeGen Flow
            img(src="photos/HalideCodeGenFlow.png" , height="500px" , style="Background:#FFFFFF")
          section
            h1 Background - OpenCL
            h2 Base on Halide CodeGen
          section
            p OpenCL is an open standard of computing for heterogeneous devices developed by Khronos Group.
            img(src="photos/InspirationForOpenCL.png",height="300px")
          section
            h3 Executing OpenCL Programs
            img(src="photos/ExecutingOpenCLPrograms.png")
          section
            h3 OpenCL in Halide CodeGen
            ol
              li <strong>init_kernels</strong> : clGetContextInfo, clGetDeviceInfo, clCreateProgramWithSource and clBuildProgram
              li <strong>device_malloc </strong> : clCreateBuffer
              li <strong>copy_to_device</strong>  : clEnqueueWriteBufferRect
              li <strong>run </strong> : clCreateKernel, clSetKernelArg, clEnqueueNDRangeKernel, clReleaseKernel and clFinish  
              li <strong>copy_to_to_host</strong>  : clEnqueueReadBufferRect
              li <strong>device_free </strong> : clReleaseMemObject.
          section
            h3 OpenCL with Multi Device 
            img(src="photos/MultiDeviceOpenCL.jpg",height="500px")
          section
            h3 Related work - FluidiCL  
          section
            h3 Architecture of FluidiCL 
            img(src="photos/FluidiCLArch.png",height="500px")
          section 
            h3 kernel Execution
            img(src="photos/FluidiCLKernelExecution.png")
        section 
          section
            h1 Implementation
          section
            h3 System Achitecture
            img(src="photos/Framework-System Architecture.png",height="600px",style="Background:#FFFFFF")
          section
            img(src="photos/OpenCL\ Comparison.png")
          section
            h3 Memory Management 
            img(src="photos/Implement-old.png",height="500px",style="background: #D8D8D8")
          section
            h3 Memory Management con'd
            img(src="photos/Implement-new.png",height="250px")
          section
            h3 Static Dispatch
            img(src="photos/StaticDispatch.png",height="500px")
          section
            h3 Dynamic Dispatch
            img(src="photos/DynamicDispatch.png",height="500px")
          section 
            h3 Usage
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              //Halide Function
              local_laplacian_gpu(levels,alpha/(levels-1),beta,input,output); //Halide GPU Function
              local_laplacian_cpu(levels,alpha/(levels-1),beta,input,output); //Halide CPU Function
              </code>
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              //Static Dispatch
              StaticDispatch static(input,output);
              static.realize(local_laplacian_cpu,local_laplacian_gpu,workload,levels,alpha/(levels-1),beta);
              </code>
            pre.
              <code class="cpp" data-trim contenteditable style="font-size: 14px;">
              //Dynamic Dispatch
              DynamicDispatch dynamic(input,output);
              dynamic.realize(local_laplacian_cpu,local_laplacian_gpu,levels,alpha/(levels-1),beta);
              </code>
        section
          section
            h1 Experiment Result
          section
            h3 Testing platform
            table 
              tr
                td Platform
                td CPU 
                td GPU
              tr
                td Android Nexus 7 
                td Quad-core 1.5 GHz Krait
                td Adreno 320
              tr
                td PC 1
                td Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz
                td ATI Radeon R7 260X
              tr 
                td PC 2 
                td Intel(R) Core(TM) i5-3470 CPU @ 3.20GHz
                td NVIDIA GTX 750
          section
            h2 Bilateral
            pre.
              <code>
              for(int j= kernelStartY; j<= kernelEndY; j++)
              {       
                for(int i= kernelStartX; i<= kernelEndX; i++)
                {                       
                unsigned int idx = max(0, min(j, height-1))*width + max(0, min(i,width-1));
                float curPix[3];
                curPix[0] = _in[idx].x;
                curPix[1] = _in[idx].y;
                curPix[2] = _in[idx].z;
                float currWeight;
                // define bilateral filter kernel weights
                float imageDist = sqrt( (float)((i-x)*(i-x) + (j-y)*(j-y)) );

                float colorDist = sqrt( (float)( (curPix[0] - ctrPix[0])*(curPix[0] - ctrPix[0]) +
                                 (curPix[1] - ctrPix[1])*(curPix[1] - ctrPix[1]) +
                                 (curPix[2] - ctrPix[2])*(curPix[2] - ctrPix[2]) ) );

                currWeight = 1.0f/(exp((imageDist/id)*(imageDist/id)*0.5)*exp((colorDist/cd)*(colorDist/cd)*0.5));
                sumWeight += currWeight;

                _sum[0] += currWeight*curPix[0]; 
                _sum[1] += currWeight*curPix[1];
                _sum[2] += currWeight*curPix[2];
                }  
              }
            </code>
          section
            h2 Local Laplacian
            img(src="photos/StateFlow_locallaplacian.png")
          section
            h2 Difference between Bilateral and Local Laplacian
            ul
              li Bilateral will refer to local area
              li Local Laplacian will refer to global area (Whole input)
          section
            h2 The influence of Workload
          section
            h3 Test input
            h4 1536*2560
            img(src="photos/gray.png",height="500px")
          section
            h3 Bilateral-Workload between CPU and GPU at Nexus 7
            img(src="photos/Result-Workload between CPU and GPU(Bilateral@Nexus7).png")
          section
            h3 Bilateral-Workload between CPU and GPU at PC 1
            img(src="photos/Result-Workload between CPU and GPU(Bilateral@PC1).png")
          section
            h3 Bilateral-Workload between CPU and GPU at PC 2
            img(src="photos/Result-Workload between CPU and GPU(Bilateral@PC2).png")
          section
            h3 Test input
            h4 1536*2560
            img(src="photos/rgb.png",height="500px")
          section
            h3 Local Laplacian-Workload between CPU and GPU at Nexus 7
            img(src="photos/Result-Workload between CPU and GPU(LocalLaplacian@Nexus7).png")
          section
            h3 Local Laplacian-Workload between CPU and GPU at PC 1
            img(src="photos/Result-Workload between CPU and GPU(LocalLaplacian@PC1).png")
          section
            h3 Local Laplacian-Workload between CPU and GPU at PC 2
            img(src="photos/Result-Workload between CPU and GPU(LocalLaplacian@PC2).png")
          section
            h2 The workload and static dispatch
          section
            h3 Bilateral-Workload and static dispatch at Nexus 7
            img(src="photos/Result-workload and static dispatch(Bilateral@Nexus7).png")
          section
            h3 Bilateral-Workload and static dispatch at PC 1 
            img(src="photos/Result-workload and static dispatch(Bilateral@PC1).png")
          section
            h3 Bilateral-Workload and static dispatch at PC 2 
            img(src="photos/Result-workload and static dispatch(Bilateral@PC2).png")
          section
            h3 Local Laplacian-Workload and static dispatch at Nexus 7
            img(src="photos/Result-workload and static dispatch(LocalLaplacian@Nexus7).png")
          section
            h3 Local Laplacian-Workload and static dispatch at PC 1
            img(src="photos/Result-workload and static dispatch(LocalLaplacian@PC1).png")
          section
            h3 Local Laplacian-Workload and static dispatch at PC 2
            img(src="photos/Result-workload and static dispatch(LocalLaplacian@PC2).png")
          section 
            h3 It turns out that
            p(class="fragment") Static Dispatch will be slower than predict execution
          section
            h2 OpenCL Profile information
          section
            h3 Execution of OpenCL API (Bilateral at PC 1)
            img(src="photos/ExecutionTimeOfAPI(Bilateal @ PC1).png")
          section
            h3 Execution of OpenCL API (Bilateral at PC 2)
            img(src="photos/ExecutionTimeOfAPI(Bilateal @ PC2).png")
          section
            h3 It shows that
            h4 The CPU usage will slow OpenCL API execution time    
          section
            h2 Dynamic Dispatch
          section
            h3 Performance of Bilateral
            img(src="photos/Performance of Bilateral.png")
          section
            h3 Performance of Local Laplacian
            img(src="photos/Performance of Local Laplacian.png")
          section 
            h2 CUDA V.S OpenCL
          section
            h3 Comparison between CUDA and OpenCL - Bilateral
            img(src="photos/Comparison between CUDA and OpenCL(Bilateral).png")
          section
            h3 Comparison between CUDA and OpenCL - Local Laplacian
            img(src="photos/Comparison between CUDA and OpenCL(Local Laplacian).png")
        section
          section 
            h1 Conclusion
          section
            h3 We create a synergistic framework base on Halide can
            ul 
              li support PC and Mobile
              li support CUDA and OpenCL
          section
            h2 Static Dispatch
          section 
            h2 When processing Bilateral Static Dispatch improves
            ul
              li(class="fragment highlight-red") <strong>21%</strong> at Nexus 7
              li(class="fragment highlight-red") <strong>66%</strong> at PC 1 &nbsp&nbsp&nbsp&nbsp&nbsp
              li(class="fragment highlight-red") <strong>16%</strong> at PC 2 &nbsp&nbsp&nbsp&nbsp&nbsp 
          section
            h2 When processing Local Laplacian Static Dispatch improves
            ul
              li(class="fragment highlight-red") <strong>24%</strong> at Nexus 7
              li(class="fragment highlight-red") <strong>3%</strong> at PC 1 &nbsp&nbsp&nbsp&nbsp&nbsp
              li(class="fragment highlight-red") <strong>11%</strong> at PC 2 &nbsp&nbsp&nbsp&nbsp&nbsp 
          section
            h2 Dynamic Dispatch
          section
            h2 When processing Bilateral Dynamic Dispatch improves
            ul
              li(class="fragment highlight-red") <strong>8%</strong>&nbsp&nbsp at Nexus 7
              li(class="fragment highlight-red") <strong>57%</strong> at PC 1 &nbsp&nbsp&nbsp&nbsp&nbsp
              li(class="fragment highlight-red") <strong>6%</strong>&nbsp&nbsp at PC 2 &nbsp&nbsp&nbsp&nbsp&nbsp 





  script(src="lib/js/head.min.js")  
  script(src="js/reveal.js")  

  script.
    Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,
      transition: 'slide', 
      dependencies: [
        { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
        { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: 'plugin/zoom-js/zoom.js', async: true },
        { src: 'plugin/notes/notes.js', async: true }
      ]
    });
